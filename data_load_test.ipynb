{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lang_list = ['chinese', 'japanese', 'thai', 'vietnamese']\n",
    "root_dir = os.environ.get('SM_CHANNEL_TRAIN', 'data')\n",
    "split = 'train'\n",
    "total_anno = dict(images=dict())\n",
    "for nation in _lang_list:\n",
    "    with open(osp.join(root_dir, '{}_receipt/ufo/{}.json'.format(nation, split)), 'r', encoding='utf-8') as f:\n",
    "        anno = json.load(f)\n",
    "    for im in anno['images']:\n",
    "        total_anno['images'][im] = anno['images'][im]\n",
    "\n",
    "anno = total_anno\n",
    "image_fnames = sorted(anno['images'].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _infer_dir(fname):\n",
    "    lang_indicator = fname.split('.')[1]\n",
    "    if lang_indicator == 'zh':\n",
    "        lang = 'chinese'\n",
    "    elif lang_indicator == 'ja':\n",
    "        lang = 'japanese'\n",
    "    elif lang_indicator == 'th':\n",
    "        lang = 'thai'\n",
    "    elif lang_indicator == 'vi':\n",
    "        lang = 'vietnamese'\n",
    "    else:\n",
    "        raise ValueError\n",
    "    return osp.join(root_dir, f'{lang}_receipt', 'img', split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_vertices(vertices, labels, ignore_under=0, drop_under=0):\n",
    "    if drop_under == 0 and ignore_under == 0:\n",
    "        return vertices, labels\n",
    "\n",
    "    new_vertices, new_labels = vertices.copy(), labels.copy()\n",
    "\n",
    "    areas = np.array([Polygon(v.reshape((4, 2))).convex_hull.area for v in vertices])\n",
    "    labels[areas < ignore_under] = 0\n",
    "\n",
    "    if drop_under > 0:\n",
    "        passed = areas >= drop_under\n",
    "        new_vertices, new_labels = new_vertices[passed], new_labels[passed]\n",
    "\n",
    "    return new_vertices, new_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_under_threshold=10\n",
    "drop_under_threshold=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import resize_img, adjust_height, rotate_img, crop_img, generate_roi_mask\n",
    "import albumentations as A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=2048\n",
    "crop_size=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 20s, sys: 1.48 s, total: 1min 21s\n",
      "Wall time: 2min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for idx in range(100):\n",
    "    image_fname = image_fnames[idx]\n",
    "    image_fpath = osp.join(_infer_dir(image_fname), image_fname)\n",
    "\n",
    "    vertices, labels = [], []\n",
    "    for word_info in anno['images'][image_fname]['words'].values():\n",
    "        num_pts = np.array(word_info['points']).shape[0]\n",
    "        if num_pts > 4:\n",
    "            continue\n",
    "        vertices.append(np.array(word_info['points']).flatten())\n",
    "        labels.append(1)\n",
    "    vertices, labels = np.array(vertices, dtype=np.float32), np.array(labels, dtype=np.int64)\n",
    "\n",
    "    vertices, labels = filter_vertices(\n",
    "        vertices,\n",
    "        labels,\n",
    "        ignore_under=ignore_under_threshold,\n",
    "        drop_under=drop_under_threshold\n",
    "    )\n",
    "\n",
    "    image = Image.open(image_fpath)\n",
    "    image, vertices = resize_img(image, vertices, image_size)\n",
    "    image, vertices = adjust_height(image, vertices)\n",
    "    image, vertices = rotate_img(image, vertices)\n",
    "    image, vertices = crop_img(image, vertices, labels, crop_size)\n",
    "\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    image = np.array(image)\n",
    "\n",
    "    \n",
    "    funcs = []\n",
    "    if True:\n",
    "        funcs.append(A.ColorJitter())\n",
    "    if True:\n",
    "        funcs.append(A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)))\n",
    "    transform = A.Compose(funcs)\n",
    "\n",
    "    image = transform(image=image)['image']\n",
    "    word_bboxes = np.reshape(vertices, (-1, 4, 2))\n",
    "    roi_mask = generate_roi_mask(image, vertices, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "A.Resize(height=image_size, width=image_size),           # resize_img 대체\n",
    "A.RandomCrop(height=crop_size, width=crop_size),         # crop_img 대체\n",
    "A.Rotate(limit=45),                                      # rotate_img 대체\n",
    "A.RandomBrightnessContrast(p=0.2),                       # 추가적인 밝기/대비 증강\n",
    "A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)), # normalize\n",
    "],\n",
    "keypoint_params=A.KeypointParams(format='xy', remove_invisible=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.53 s, sys: 1.45 s, total: 7.98 s\n",
      "Wall time: 9.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for idx in range(100):\n",
    "    image_fname = image_fnames[idx]\n",
    "    image_fpath = osp.join(_infer_dir(image_fname), image_fname)\n",
    "    # print(image_fpath)\n",
    "    vertices, labels = [], []\n",
    "    for word_info in anno['images'][image_fname]['words'].values():\n",
    "        num_pts = np.array(word_info['points']).shape[0]\n",
    "        if num_pts > 4:\n",
    "            continue\n",
    "        vertices.append(np.array(word_info['points']).flatten())\n",
    "        labels.append(1)\n",
    "    vertices, labels = np.array(vertices, dtype=np.float32), np.array(labels, dtype=np.int64)\n",
    "\n",
    "    vertices, labels = filter_vertices(\n",
    "        vertices,\n",
    "        labels,\n",
    "        ignore_under=ignore_under_threshold,\n",
    "        drop_under=drop_under_threshold\n",
    "    )\n",
    "    image = Image.open(image_fpath)\n",
    "    # if image.mode != 'RGB':\n",
    "    #     image = image.convert('RGB')\n",
    "    image = np.array(image)\n",
    "\n",
    "\n",
    "    augmented = transform(image=image, keypoints=vertices)\n",
    "\n",
    "    image = augmented['image']\n",
    "\n",
    "    word_bboxes = augmented['keypoints']\n",
    "\n",
    "\n",
    "    # word_bboxes = np.array([transform.apply_to_coords(x, y) for x, y in word_bboxes]).flatten()\n",
    "    \n",
    "    roi_mask = generate_roi_mask(image, vertices, labels)\n",
    "    # return image, word_bboxes, roi_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': array([[[0.4666667 , 0.34117648, 0.16078432],\n",
       "         [0.4666667 , 0.34117648, 0.16078432],\n",
       "         [0.4666667 , 0.34117648, 0.16078432],\n",
       "         ...,\n",
       "         [0.427451  , 0.30980393, 0.12941177],\n",
       "         [0.427451  , 0.30980393, 0.14509805],\n",
       "         [0.427451  , 0.30980393, 0.14509805]],\n",
       " \n",
       "        [[0.4666667 , 0.34117648, 0.16078432],\n",
       "         [0.4666667 , 0.34117648, 0.16078432],\n",
       "         [0.4666667 , 0.34117648, 0.16078432],\n",
       "         ...,\n",
       "         [0.41960788, 0.3019608 , 0.12156864],\n",
       "         [0.41960788, 0.3019608 , 0.12941177],\n",
       "         [0.427451  , 0.30980393, 0.14509805]],\n",
       " \n",
       "        [[0.4666667 , 0.34117648, 0.16078432],\n",
       "         [0.4666667 , 0.34117648, 0.16078432],\n",
       "         [0.4666667 , 0.34117648, 0.16078432],\n",
       "         ...,\n",
       "         [0.41960788, 0.3019608 , 0.12156864],\n",
       "         [0.41960788, 0.3019608 , 0.12156864],\n",
       "         [0.41176474, 0.29411766, 0.12156864]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.3803922 , 0.2627451 , 0.09803922],\n",
       "         [0.3803922 , 0.2627451 , 0.09803922],\n",
       "         [0.3803922 , 0.2627451 , 0.09803922],\n",
       "         ...,\n",
       "         [0.34117648, 0.22352943, 0.05882353],\n",
       "         [0.33333334, 0.21568629, 0.0509804 ],\n",
       "         [0.34117648, 0.22352943, 0.05882353]],\n",
       " \n",
       "        [[0.3803922 , 0.2627451 , 0.09803922],\n",
       "         [0.37254903, 0.25490198, 0.09019608],\n",
       "         [0.3647059 , 0.24705884, 0.08235294],\n",
       "         ...,\n",
       "         [0.34117648, 0.22352943, 0.05882353],\n",
       "         [0.34901962, 0.23137257, 0.06666667],\n",
       "         [0.34901962, 0.23137257, 0.06666667]],\n",
       " \n",
       "        [[0.3647059 , 0.2392157 , 0.08235294],\n",
       "         [0.35686275, 0.2392157 , 0.07450981],\n",
       "         [0.35686275, 0.2392157 , 0.07450981],\n",
       "         ...,\n",
       "         [0.34901962, 0.23137257, 0.06666667],\n",
       "         [0.34901962, 0.23137257, 0.06666667],\n",
       "         [0.34117648, 0.22352943, 0.05882353]]], dtype=float32)}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
