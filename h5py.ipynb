{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.20 (you have 1.4.12). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "INFO:matplotlib.font_manager:generated new fontManager\n"
     ]
    }
   ],
   "source": [
    "from dataset import SceneTextDataset\n",
    "import albumentations as A\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import json\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "from dataset import resize_img, adjust_height, rotate_img, crop_img, generate_roi_mask\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lang_list = ['chinese', 'japanese', 'thai', 'vietnamese']\n",
    "root_dir = os.environ.get('SM_CHANNEL_TRAIN', 'data')\n",
    "split = 'train'\n",
    "total_anno = dict(images=dict())\n",
    "for nation in _lang_list:\n",
    "    with open(osp.join(root_dir, '{}_receipt/ufo/{}.json'.format(nation, split)), 'r', encoding='utf-8') as f:\n",
    "        anno = json.load(f)\n",
    "    for im in anno['images']:\n",
    "        total_anno['images'][im] = anno['images'][im]\n",
    "\n",
    "anno = total_anno\n",
    "image_fnames = sorted(anno['images'].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _infer_dir(fname):\n",
    "    lang_indicator = fname.split('.')[1]\n",
    "    if lang_indicator == 'zh':\n",
    "        lang = 'chinese'\n",
    "    elif lang_indicator == 'ja':\n",
    "        lang = 'japanese'\n",
    "    elif lang_indicator == 'th':\n",
    "        lang = 'thai'\n",
    "    elif lang_indicator == 'vi':\n",
    "        lang = 'vietnamese'\n",
    "    else:\n",
    "        raise ValueError\n",
    "    return osp.join(root_dir, f'{lang}_receipt', 'img', split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_under_threshold=10\n",
    "drop_under_threshold=1\n",
    "image_size=2048\n",
    "crop_size=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SceneTextDataset(\n",
    "root_dir,\n",
    "split='train',\n",
    "image_size=image_size,\n",
    "crop_size=crop_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from east_dataset import generate_score_geo_maps\n",
    "import cv2\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.57 s, sys: 4.61 s, total: 9.18 s\n",
      "Wall time: 1.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "map_scale=0.5\n",
    "# for idx in range(1,2):\n",
    "idx = 3\n",
    "image, word_bboxes, roi_mask = train_dataset[idx]\n",
    "score_map, geo_map = generate_score_geo_maps(image, word_bboxes, map_scale=map_scale)\n",
    "\n",
    "mask_size = int(image.shape[0] * map_scale), int(image.shape[1] * map_scale)\n",
    "roi_mask = cv2.resize(roi_mask, dsize=mask_size)\n",
    "if roi_mask.ndim == 2:\n",
    "    roi_mask = np.expand_dims(roi_mask, axis=2)\n",
    "\n",
    "if True:\n",
    "    image = torch.Tensor(image).permute(2, 0, 1)\n",
    "    score_map = torch.Tensor(score_map).permute(2, 0, 1)\n",
    "    geo_map = torch.Tensor(geo_map).permute(2, 0, 1)\n",
    "    roi_mask = torch.Tensor(roi_mask).permute(2, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
