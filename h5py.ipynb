{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.20 (you have 1.4.12). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from dataset import SceneTextDataset\n",
    "import albumentations as A\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import json\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "from dataset import resize_img, adjust_height, rotate_img, crop_img, generate_roi_mask\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from east_dataset import generate_score_geo_maps\n",
    "import cv2\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lang_list = ['chinese', 'japanese', 'thai', 'vietnamese']\n",
    "root_dir = os.environ.get('SM_CHANNEL_TRAIN', 'data')\n",
    "split = 'train'\n",
    "total_anno = dict(images=dict())\n",
    "for nation in _lang_list:\n",
    "    with open(osp.join(root_dir, '{}_receipt/ufo/{}.json'.format(nation, split)), 'r', encoding='utf-8') as f:\n",
    "        anno = json.load(f)\n",
    "    for im in anno['images']:\n",
    "        total_anno['images'][im] = anno['images'][im]\n",
    "\n",
    "anno = total_anno\n",
    "image_fnames = sorted(anno['images'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _infer_dir(fname):\n",
    "    lang_indicator = fname.split('.')[1]\n",
    "    if lang_indicator == 'zh':\n",
    "        lang = 'chinese'\n",
    "    elif lang_indicator == 'ja':\n",
    "        lang = 'japanese'\n",
    "    elif lang_indicator == 'th':\n",
    "        lang = 'thai'\n",
    "    elif lang_indicator == 'vi':\n",
    "        lang = 'vietnamese'\n",
    "    else:\n",
    "        raise ValueError\n",
    "    return osp.join(root_dir, f'{lang}_receipt', 'img', split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_under_threshold=10\n",
    "drop_under_threshold=1\n",
    "image_size=2048\n",
    "crop_size=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_vertices(vertices, labels, ignore_under=0, drop_under=0):\n",
    "    if drop_under == 0 and ignore_under == 0:\n",
    "        return vertices, labels\n",
    "\n",
    "    new_vertices, new_labels = vertices.copy(), labels.copy()\n",
    "\n",
    "    areas = np.array([Polygon(v.reshape((4, 2))).convex_hull.area for v in vertices])\n",
    "    labels[areas < ignore_under] = 0\n",
    "\n",
    "    if drop_under > 0:\n",
    "        passed = areas >= drop_under\n",
    "        new_vertices, new_labels = new_vertices[passed], new_labels[passed]\n",
    "\n",
    "    return new_vertices, new_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SceneTextWoAugDataset(Dataset):\n",
    "    def __init__(self, root_dir,\n",
    "                 split='train',\n",
    "                 ignore_under_threshold=10,\n",
    "                 drop_under_threshold=1,\n",
    "                 ):\n",
    "        self._lang_list = ['chinese', 'japanese', 'thai', 'vietnamese']\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        total_anno = dict(images=dict())\n",
    "        for nation in self._lang_list:\n",
    "            with open(osp.join(root_dir, '{}_receipt/ufo/{}.json'.format(nation, split)), 'r', encoding='utf-8') as f:\n",
    "                anno = json.load(f)\n",
    "            for im in anno['images']:\n",
    "                total_anno['images'][im] = anno['images'][im]\n",
    "\n",
    "        self.anno = total_anno\n",
    "        self.image_fnames = sorted(self.anno['images'].keys())\n",
    "\n",
    "        self.drop_under_threshold = drop_under_threshold\n",
    "        self.ignore_under_threshold = ignore_under_threshold\n",
    "\n",
    "        self.vertices_list = []\n",
    "        self.labels_list = []\n",
    "        self.images_list = []\n",
    "\n",
    "        for idx in range(len(self.image_fnames)):\n",
    "            image_fname = self.image_fnames[idx]\n",
    "            image_fpath = osp.join(self._infer_dir(image_fname), image_fname)\n",
    "\n",
    "            vertices, labels = [], []\n",
    "            for word_info in self.anno['images'][image_fname]['words'].values():\n",
    "                num_pts = np.array(word_info['points']).shape[0]\n",
    "                if num_pts > 4:\n",
    "                    continue\n",
    "                vertices.append(np.array(word_info['points']).flatten())\n",
    "                labels.append(1)\n",
    "            vertices, labels = np.array(vertices, dtype=np.float32), np.array(labels, dtype=np.int64)\n",
    "\n",
    "            vertices, labels = filter_vertices(\n",
    "                vertices,\n",
    "                labels,\n",
    "                ignore_under=self.ignore_under_threshold,\n",
    "                drop_under=self.drop_under_threshold\n",
    "            )\n",
    "\n",
    "            image = Image.open(image_fpath)\n",
    "      \n",
    "            \n",
    "            self.vertices_list.append(vertices)\n",
    "            self.labels_list.append(labels)\n",
    "            self.images_list.append(image)\n",
    "\n",
    "\n",
    "        self.vertices = np.array(self.vertices_list, dtype=object)\n",
    "        self.labels = np.array(self.labels_list, dtype=object)\n",
    "        self.images = np.array(self.images_list, dtype=object)\n",
    "\n",
    "\n",
    "    def _infer_dir(self, fname):\n",
    "        lang_indicator = fname.split('.')[1]\n",
    "        if lang_indicator == 'zh':\n",
    "            lang = 'chinese'\n",
    "        elif lang_indicator == 'ja':\n",
    "            lang = 'japanese'\n",
    "        elif lang_indicator == 'th':\n",
    "            lang = 'thai'\n",
    "        elif lang_indicator == 'vi':\n",
    "            lang = 'vietnamese'\n",
    "        else:\n",
    "            raise ValueError\n",
    "        return osp.join(self.root_dir, f'{lang}_receipt', 'img', self.split)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_fnames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "\n",
    "        image, vertices, labels = self.images[idx], self.vertices[idx], self.labels[idx]\n",
    "\n",
    "        # image, vertices = resize_img(image, vertices, self.image_size)\n",
    "        # image, vertices = adjust_height(image, vertices)\n",
    "        # image, vertices = rotate_img(image, vertices)\n",
    "        # image, vertices = crop_img(image, vertices, labels, self.crop_size)\n",
    "\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "\n",
    "        image = np.array(image)\n",
    "\n",
    "        funcs = []\n",
    "        if True:\n",
    "            funcs.append(A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)))\n",
    "        transform = A.Compose(funcs)\n",
    "\n",
    "        image = transform(image=image)['image']\n",
    "\n",
    "        word_bboxes = np.array(vertices).reshape(-1, 4, 2)\n",
    "        roi_mask = generate_roi_mask(image, vertices, labels)\n",
    "\n",
    "        # print(\"shape\",image.shape)\n",
    "\n",
    "        return image, word_bboxes, roi_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_398431/3477511670.py:57: FutureWarning: The input object of type 'JpegImageFile' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'JpegImageFile', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  self.images = np.array(self.images_list, dtype=object)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SceneTextWoAugDataset(\n",
    "root_dir,\n",
    "split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from east_dataset import EASTDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EASTDataset(train_dataset,to_tensor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset_to_h5py(dataset, h5py_filename=\"east_dataset.h5\", batch_size=16):\n",
    "    # dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # h5py 파일 생성\n",
    "    with h5py.File(h5py_filename, 'w') as h5file:\n",
    "        # 각 데이터 타입의 그룹 생성\n",
    "        image_group = h5file.create_group('images')\n",
    "        score_map_group = h5file.create_group('score_maps')\n",
    "        geo_map_group = h5file.create_group('geo_maps')\n",
    "        roi_mask_group = h5file.create_group('roi_masks')\n",
    "\n",
    "        # 인덱스 초기화\n",
    "        idx = 0\n",
    "\n",
    "        # 배치 단위로 데이터 저장\n",
    "        for idx in tqdm(range(len(dataset))):\n",
    "            image, score_map, geo_map, roi_mask = dataset[idx]\n",
    "\n",
    "\n",
    "            # 각 배치의 데이터 저장\n",
    "            image_group.create_dataset(str(idx), data=image)\n",
    "            score_map_group.create_dataset(str(idx), data=score_map)\n",
    "            geo_map_group.create_dataset(str(idx), data=geo_map)\n",
    "            roi_mask_group.create_dataset(str(idx), data=roi_mask)\n",
    "\n",
    "    print(f\"Dataset saved to {h5py_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 5/400 [00:46<1:06:48, 10.15s/it]"
     ]
    }
   ],
   "source": [
    "save_dataset_to_h5py(dataset, h5py_filename=\"east_dataset.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
